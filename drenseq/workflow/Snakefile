import pandas as pd
from Bio import SeqIO

configfile: "config/config.yaml"

samples=pd.read_table(config["samples"], header=0).set_index(["sample"], drop=False)

if samples.duplicated(subset=["sample"]).any():
    sys.exit("Duplicate sample in samples file, check your inputs!")




def get_F_Reads(wildcards):
    return samples["FRead"][wildcards.sample]


def get_R_Reads(wildcards):
    return samples["RRead"][wildcards.sample]


def get_samples(wildcards):
    return samples["sample"][wildcards.sample]


rule all:
    input:
        "coverage/all_coverage_values_transposed.txt"


rule extract_reference_headers:
    input:
        config["Reference_Fasta"]
    output:
        "resources/reference_headers.txt"
    log:
        "logs/initial_grep/log.txt"
    resources:
        mem_mb=2000
    run:
        shell("""echo "gene" > {output}""")
        shell("""(cat {input} | grep '>' | sed 's/>//g' >> {output}) 2> {log}""")


rule trim_read_remove_adaptor:
    input:
        fastqF=get_F_Reads,
        fastqR=get_R_Reads,
        adaptor_1=config["adaptor_path_1"],
        adaptor_2=config["adaptor_path_2"]
    output:
        trimF=temp("trimmed_reads/{sample}/R1.fq"),
        trimR=temp("trimmed_reads/{sample}/R2.fq")
    log:
        "logs/cutadapt/{sample}.log"
    threads:
        8
    resources:
        mem_mb=4000
    conda:
        "envs/cutadapt.yaml"
    shell:
        "cutadapt --cores {threads} --minimum-length 50 -q 20,20 -a "
        "file:{input.adaptor_1} -A file:{input.adaptor_2} -o "
        "{output.trimF} -p {output.trimR} {input.fastqF} "
        "{input.fastqR} > {log}"


rule bowtie_build:
    input:
        ref=config["Reference_Fasta"]
    output:
        index=multiext(config["Reference_Fasta"], ".1.bt2", ".2.bt2", ".3.bt2", ".4.bt2", ".rev.1.bt2", ".rev.2.bt2")
    conda:
        "envs/bowtie2_samtools.yaml"
    log:
        "logs/bowtie2/indexing.log"
    resources:
        mem_mb=4000
    shell:
        "(bowtie2-build {input} {input}) 2> {log}"


rule bowtie_align:
    input:
        ref=config["Reference_Fasta"],
        FRead="trimmed_reads/{sample}/R1.fq",
        RRead="trimmed_reads/{sample}/R2.fq",
        index=config["Reference_Fasta"] + ".1.bt2"
    params:
        rg_id="{sample}",
        rg="SM:{sample}",
        score=config["scoreMinRelaxed"],
        max_align=config["maximum_alignments"]
    threads:
        8
    resources:
        mem_mb=4000
    conda:
        "envs/bowtie2_samtools.yaml"
    output:
        temp("tmp_mappings/{sample}.bam")
    log:
        "logs/bowtie2/{sample}.log"
    shell:
        "(bowtie2 -x {input.ref} -1 {input.FRead} -2 {input.RRead} --rg-id "
        "{params.rg_id} --rg {params.rg} -p {threads} --score-min "
        "{params.score} --phred33 --fr --maxins 1000 --very-sensitive "
        "--no-unal --no-discordant -k {params.max_align} | samtools view --threads {threads} "
        "-S -b > {output}) 2> {log}"


rule samtools_sort:
    input:
        "tmp_mappings/{sample}.bam"
    threads:
        8
    resources:
        mem_mb=8000
    output:
        "mappings/{sample}_sorted.bam"
    conda:
        "envs/bowtie2_samtools.yaml"
    log:
        "logs/samtools_sort/{sample}.log"
    shell:
        "(samtools sort --threads {threads} -l 9 {input} -o {output}) "
        "> {log}"


rule samtools_index_relaxed:
    input:
        "mappings/{sample}_sorted.bam"
    output:
        "mappings/{sample}_sorted.bam.bai"
    conda:
        "envs/bowtie2_samtools.yaml"
    log:
        "logs/samtools_index_relaxed/{sample}.log"
    resources:
        mem_mb=4000
    shell:
        "(samtools index {input} {output}) > {log}"


rule sambamba_filter:
    input:
        bam="mappings/{sample}_sorted.bam",
        bai="mappings/{sample}_sorted.bam.bai"
    output:
        "mappings/{sample}_strict.bam"
    conda:
        "envs/sambamba.yaml"
    log:
        "logs/sambamba/{sample}.log"
    resources:
        mem_mb=4000
    shell:
        """(sambamba view --format=bam -l 9 --filter='[NM] == 0' -o {output} {input.bam}) > {log}"""


rule samtools_index_strict:
    input:
        "mappings/{sample}_strict.bam"
    output:
        "mappings/{sample}_strict.bam.bai"
    conda:
        "envs/bowtie2_samtools.yaml"
    log:
        "logs/samtools_index_strict/{sample}.log"
    resources:
        mem_mb=4000
    shell:
        "(samtools index {input} {output}) > {log}"


rule coverage_strict:
    input:
        bam="mappings/{sample}_strict.bam",
        bed=config["CDS_Bed"],
        bai="mappings/{sample}_strict.bam.bai"
    output:
        "coverage/{sample}_coverage.txt"
    conda:
        "envs/bedtools.yaml"
    log:
        "logs/bedtools/{sample}.log"
    resources:
        mem_mb=4000
    shell:
        "(coverageBed -d -a {input.bed} -b {input.bam} > {output}) 2> {log}"


rule per_gene_coverage:
    input:
        referenceGenes="resources/reference_headers.txt",
        sample_coverage="coverage/{sample}_coverage.txt"
    output:
        gene_coverage="coverage/{sample}_geneCoverage.txt"
    log:
        "logs/coverage_gathering/{sample}_per_gene_coverage.log"
    resources:
        mem_mb=2000
    shell:
        """(cat {input.referenceGenes} | tail -n +2 | while read gene; do numPosWithCoverage=`grep -w "$gene" {input.sample_coverage} | awk '$5>0' | wc -l`; numPosTotal=`grep -w "$gene" {input.sample_coverage} | wc -l`; if [ $numPosTotal -eq 0 ]; then echo "ERROR: gene $gene has CDS region of length zero. Check your input data (e.g. gene spelling in FASTA and CDS BED file) and retry.\nAborting pipeline run."; exit; fi; pctCov=`awk "BEGIN {{print ($numPosWithCoverage/$numPosTotal)*100 }}"`; echo -e "\n# covered positions for sample {wildcards.sample} in gene $gene: $numPosWithCoverage\n# CDS positions for gene $gene: $numPosTotal\npctCov: $pctCov"; echo -e "$gene\t$pctCov" >> {output.gene_coverage}; done) 2> {log}"""


rule combine_gene_coverage:
    input:
        "coverage/{sample}_geneCoverage.txt"
    output:
        "coverage/{sample}_coverageValues.txt"
    log:
        "logs/coverage_gathering/{sample}_combine_gene_coverage.log"
    resources:
        mem_mb=2000
    run:
        shell("(echo {wildcards.sample} > {output}) 2> {log}")
        shell("(cat {input} | cut -f2 >> {output}) 2>> {log}")


rule combine_coverage_values:
    input:
        gene_names="resources/reference_headers.txt",
        coverage=expand("coverage/{sample}_coverageValues.txt", sample=samples["sample"])
    output:
        "coverage/all_coverage_values.txt"
    log:
        "logs/coverage_gathering/combine_coverage_values.log"
    params:
        ulimit=config["ulimit"]
    resources:
        mem_mb=2000
    shell:
        """ulimit -n {params.ulimit}
        (paste {input.gene_names} {input.coverage} > {output}) 2> {log}"""


rule transpose_combined_coverage:
    input:
        "coverage/all_coverage_values.txt"
    output:
        "coverage/all_coverage_values_transposed.txt"
    log:
        "logs/coverage_gathering/transposing.log"
    resources:
        mem_mb=2000
    run:
        df = pd.read_table(input[0], header = None)
        df.T.to_csv(output[0], sep = "\t", header = False, index = False)
